.\" Automatically generated by Pod::Man v1.37, Pod::Parser v1.32
.\"
.\" Standard preamble:
.\" ========================================================================
.de Sh \" Subsection heading
.br
.if t .Sp
.ne 5
.PP
\fB\\$1\fR
.PP
..
.de Sp \" Vertical space (when we can't use .PP)
.if t .sp .5v
.if n .sp
..
.de Vb \" Begin verbatim text
.ft CW
.nf
.ne \\$1
..
.de Ve \" End verbatim text
.ft R
.fi
..
.\" Set up some character translations and predefined strings.  \*(-- will
.\" give an unbreakable dash, \*(PI will give pi, \*(L" will give a left
.\" double quote, and \*(R" will give a right double quote.  \*(C+ will
.\" give a nicer C++.  Capital omega is used to do unbreakable dashes and
.\" therefore won't be available.  \*(C` and \*(C' expand to `' in nroff,
.\" nothing in troff, for use with C<>.
.tr \(*W-
.ds C+ C\v'-.1v'\h'-1p'\s-2+\h'-1p'+\s0\v'.1v'\h'-1p'
.ie n \{\
.    ds -- \(*W-
.    ds PI pi
.    if (\n(.H=4u)&(1m=24u) .ds -- \(*W\h'-12u'\(*W\h'-12u'-\" diablo 10 pitch
.    if (\n(.H=4u)&(1m=20u) .ds -- \(*W\h'-12u'\(*W\h'-8u'-\"  diablo 12 pitch
.    ds L" ""
.    ds R" ""
.    ds C` ""
.    ds C' ""
'br\}
.el\{\
.    ds -- \|\(em\|
.    ds PI \(*p
.    ds L" ``
.    ds R" ''
'br\}
.\"
.\" If the F register is turned on, we'll generate index entries on stderr for
.\" titles (.TH), headers (.SH), subsections (.Sh), items (.Ip), and index
.\" entries marked with X<> in POD.  Of course, you'll have to process the
.\" output yourself in some meaningful fashion.
.if \nF \{\
.    de IX
.    tm Index:\\$1\t\\n%\t"\\$2"
..
.    nr % 0
.    rr F
.\}
.\"
.\" For nroff, turn off justification.  Always turn off hyphenation; it makes
.\" way too many mistakes in technical documents.
.hy 0
.if n .na
.\"
.\" Accent mark definitions (@(#)ms.acc 1.5 88/02/08 SMI; from UCB 4.2).
.\" Fear.  Run.  Save yourself.  No user-serviceable parts.
.    \" fudge factors for nroff and troff
.if n \{\
.    ds #H 0
.    ds #V .8m
.    ds #F .3m
.    ds #[ \f1
.    ds #] \fP
.\}
.if t \{\
.    ds #H ((1u-(\\\\n(.fu%2u))*.13m)
.    ds #V .6m
.    ds #F 0
.    ds #[ \&
.    ds #] \&
.\}
.    \" simple accents for nroff and troff
.if n \{\
.    ds ' \&
.    ds ` \&
.    ds ^ \&
.    ds , \&
.    ds ~ ~
.    ds /
.\}
.if t \{\
.    ds ' \\k:\h'-(\\n(.wu*8/10-\*(#H)'\'\h"|\\n:u"
.    ds ` \\k:\h'-(\\n(.wu*8/10-\*(#H)'\`\h'|\\n:u'
.    ds ^ \\k:\h'-(\\n(.wu*10/11-\*(#H)'^\h'|\\n:u'
.    ds , \\k:\h'-(\\n(.wu*8/10)',\h'|\\n:u'
.    ds ~ \\k:\h'-(\\n(.wu-\*(#H-.1m)'~\h'|\\n:u'
.    ds / \\k:\h'-(\\n(.wu*8/10-\*(#H)'\z\(sl\h'|\\n:u'
.\}
.    \" troff and (daisy-wheel) nroff accents
.ds : \\k:\h'-(\\n(.wu*8/10-\*(#H+.1m+\*(#F)'\v'-\*(#V'\z.\h'.2m+\*(#F'.\h'|\\n:u'\v'\*(#V'
.ds 8 \h'\*(#H'\(*b\h'-\*(#H'
.ds o \\k:\h'-(\\n(.wu+\w'\(de'u-\*(#H)/2u'\v'-.3n'\*(#[\z\(de\v'.3n'\h'|\\n:u'\*(#]
.ds d- \h'\*(#H'\(pd\h'-\w'~'u'\v'-.25m'\f2\(hy\fP\v'.25m'\h'-\*(#H'
.ds D- D\\k:\h'-\w'D'u'\v'-.11m'\z\(hy\v'.11m'\h'|\\n:u'
.ds th \*(#[\v'.3m'\s+1I\s-1\v'-.3m'\h'-(\w'I'u*2/3)'\s-1o\s+1\*(#]
.ds Th \*(#[\s+2I\s-2\h'-\w'I'u*3/5'\v'-.3m'o\v'.3m'\*(#]
.ds ae a\h'-(\w'a'u*4/10)'e
.ds Ae A\h'-(\w'A'u*4/10)'E
.    \" corrections for vroff
.if v .ds ~ \\k:\h'-(\\n(.wu*9/10-\*(#H)'\s-2\u~\d\s+2\h'|\\n:u'
.if v .ds ^ \\k:\h'-(\\n(.wu*10/11-\*(#H)'\v'-.4m'^\v'.4m'\h'|\\n:u'
.    \" for low resolution devices (crt and lpr)
.if \n(.H>23 .if \n(.V>19 \
\{\
.    ds : e
.    ds 8 ss
.    ds o a
.    ds d- d\h'-1'\(ga
.    ds D- D\h'-1'\(hy
.    ds th \o'bp'
.    ds Th \o'LP'
.    ds ae ae
.    ds Ae AE
.\}
.rm #[ #] #H #V #F C
.\" ========================================================================
.\"
.IX Title "TermExtract::JapanesePlainTextSJIS 3pm"
.TH TermExtract::JapanesePlainTextSJIS 3pm "2005-07-14" "perl v5.8.8" "User Contributed Perl Documentation"
.SH "NAME"
.Vb 2
\&    TermExtract::JapanesePlainTextSJIS
\&     \-\- 専門用語自動抽出モジュール（和文「カタカナ・漢字抽出方式」SJIS版）
.Ve
.SH "SYNOPSIS"
.IX Header "SYNOPSIS"
.Vb 1
\&    use TermExtract::JapanesePlainTextSJIS;
.Ve
.SH "DESCRIPTION"
.IX Header "DESCRIPTION"
.Vb 1
\&    日本語のテキストデータ（SJIS)からそのまま専門用語を抽出するプログラム。
.Ve
.PP
.Vb 2
\&    当モジュールの使用法については、親クラス（TermExtract::Calc_Imp)か、
\&  以下のサンプルスクリプトを参照のこと。
.Ve
.Sh "Sample Script"
.IX Subsection "Sample Script"
.Vb 1
\& #!/usr/local/bin/perl \-w
.Ve
.PP
.Vb 9
\& #
\& #  ex_JPTS.pl
\& #
\& #  標準出力に専門用語とその重要度を返すプログラム
\& #  和文「カタカナ・漢字抽出方式」Shif\-JIS版
\& #
\& #   version 0.04
\& #
\& #
.Ve
.PP
.Vb 4
\& use TermExtract::JapanesePlainTextSJIS;
\& #use strict;
\& my $data = new TermExtract::JapanesePlainTextSJIS;
\& my $InputFile = "JPTS_out.txt";    # 入力ファイル
.Ve
.PP
.Vb 3
\& # プロセスの異常終了時処理
\& # (ロックディレクトリを使用した場合のみ）
\& $SIG{INT} = $SIG{QUIT} = $SIG{TERM} = \(aqsigexit\(aq;
.Ve
.PP
.Vb 4
\& # 出力モードを指定
\& # 1 → 専門用語＋重要度、2 → 専門用語のみ
\& # 3 → カンマ区切り
\& my $output_mode = 1;
.Ve
.PP
.Vb 11
\& #
\& # 重要度計算で、連接語の"延べ数"、"異なり数"、"パープレキシティ"のい
\& # ずれをとるか選択。パープレキシティは「学習機能e」を使えない
\& # また、"連接語の情報を使わない"選択もあり、この場合は用語出現回数
\& # (と設定されていればIDFの組み合わせ）で重要度計算を行う
\& # （デフォルトは"延べ数"をとる $obj\->use_total)
\& #
\& #$data\->use_total;      # 延べ数をとる
\& #$data\->use_uniq;       # 異なり数をとる
\& #$data\->use_Perplexity; # パープレキシティをとる(TermExtract 3.04 以上)
\& #$data\->no_LR;          # 隣接情報を使わない (TermExtract 4.02 以上)
.Ve
.PP
.Vb 10
\& #
\& # 重要度計算で、連接情報に掛け合わせる用語出現頻度情報を選択する
\& # $data\->no_LR; との組み合わせで用語出現頻度のみの重要度も算出可能e
\& # （デフォルトは "Frequency" $data\->use_frq)
\& # TFはある用語が他の用語の一部に使われていた場合にもカウント
\& # Frequency は用語が他の用語の一部に使われていた場合にカウントしない
\& #
\& #$data\->use_TF;   # TF (Term Frequency) (TermExtract 4.02 以上)
\& #$data\->use_frq;  # Frequencyによる用語頻度
\& #$data\->no_frq;   # 頻度情報を使わない
.Ve
.PP
.Vb 6
\& #
\& # 重要度計算で、学習機能eを使うかどうか選択
\& # （デフォルトは、使用しない $obj\->no_stat)
\& #
\& #$data\->use_stat; # 学習機能eを使う
\& #$data\->no_stat;  # 学習機能eを使わない
.Ve
.PP
.Vb 7
\& #
\& # 重要度計算で、「ドキュメント中の用語の頻度」と「連接語の重要度」
\& # のどちらに比重をおくかを設定する。
\& # デフォルト値は１
\& # 値が大きいほど「ドキュメント中の用語の頻度」の比重が高まる
\& #
\& #$data\->average_rate(0.5);
.Ve
.PP
.Vb 9
\& #
\& # 学習機能e用DBにデータを蓄積するかどうか選択
\& # 重要度計算で、学習機能eを使うときは、セットしておいたほうが
\& # 無難。処理対象に学習機能e用DBに登録されていない語が含まれる
\& # と正しく動作しない。
\& # （デフォルトは、蓄積しない $obj\->no_storage）
\& #
\& #$data\->use_storage; # 蓄積する
\& #$data\->no_storage;  # 蓄積しない
.Ve
.PP
.Vb 5
\& #
\& # 学習機能e用DBに使用するDBMをSDBM_Fileに指定
\& # （デフォルトは、DB_FileのBTREEモード）
\& #
\& #$data\->use_SDBM;
.Ve
.PP
.Vb 7
\& #
\& # 過去のドキュメントの累積統計を使う場合のデータベースの
\& # ファイル名をセット
\& # （デフォルトは "stat.db"と"comb.db"）
\& #
\& #$data\->stat_db("statUC.db");
\& #$data\->comb_db("combUC.db");
.Ve
.PP
.Vb 5
\& #
\& # データベースの排他ロックのための一時ディレクトリを指定
\& # ディレクトリ名が空文字列（デフォルト）の場合はロックしない
\& #
\& #$data\->lock_dir("lock_dir");
.Ve
.PP
.Vb 7
\& #
\& # データを読み込み
\& # 専門用語リストを配列に返す
\& # （累積統計DB使用、ドキュメント中の頻度使用にセット）
\& #
\& #my @noun_list = $data\->get_imp_word($str, \(aqvar\(aq);     # 入力が変数
\& my @noun_list = $data\->get_imp_word($InputFile); # 入力がファイル
.Ve
.PP
.Vb 7
\& #
\& # 前回読み込んだテキストファイルを元に
\& # モードを変えて、専門用語リストを配列に返す
\& #$data\->use_stat\->no_frq;
\& #my @noun_list2 = $data\->get_imp_word();
\& # また、その結果を別のモードによる結果と掛け合わせる
\& #@noun_list = $data\->result_filter (\e@noun_list, \e@noun_list2, 30, 1000);
.Ve
.PP
.Vb 6
\& #
\& #  専門用語リストと計算した重要度を標準出力に出す
\& #
\& foreach (@noun_list) {
\&    # 日付・時刻は表e示しない
\&    next if $_\->[0] =~ /^(昭和)*(平成)*(\ed+年)*(\ed+月)*(\ed+日)*(午前)*(午後)*(\ed+時)*(\ed+分)*(\ed+秒)*$/;
.Ve
.PP
.Vb 2
\&    # 数値のみは表e示しない
\&    next if $_\->[0] =~ /^\ed+$/;
.Ve
.PP
.Vb 5
\&    # 結果表e示（$output_modeに応じて、出力様式を変更
\&    printf "%\-60s %16.2f\en", $_\->[0], $_\->[1] if $output_mode == 1;
\&    printf "%s\en",           $_\->[0]          if $output_mode == 2;
\&    printf "%s,",            $_\->[0]          if $output_mode == 3;
\& }
.Ve
.SH "Methods"
.IX Header "Methods"
.Vb 5
\&    このモジュールでは、get_imp_word のみ実装し、それ以外のメソeッドは親
\&  モジュール TermExtract::Calc_Imp で実装されている。
\&    get_imp_word はストップワードにより文章を複合語の単位までに分割して
\&  いる。それ以外のメソeッドについては、TermExtract::Calc_Imp のPODドキュ
\&  メントを参照すること。
.Ve
.Sh "get_imp_word"
.IX Subsection "get_imp_word"
.Vb 5
\&    日本語の文章から次のルールにより複合語を抽出する。第１引数は、処理
\&  対象のデータ、第２引数は第１引数の種別である。デフォルトでは、第１引
\&  数は、日本語語のテキストファイルとなる。第２引数に文字列\(aqvar\(aqがセット
\&  されたときには、第一引数を日本語のテキストデータが入ったスカラー変数
\&  と解釈する。
.Ve
.PP
.Vb 7
\&    （１）連続した「漢字」、「カタカナ」、「英字及び１バイト記号」を抽
\&　　　　出する。
\&     (２）改行があった場合は、そこで複合語の区切りとする
\&    （３）「漢字」は１文字単位、「カタカナ」及び「英字及び１バイト記号
\&　　　　」、は語単位でまとまりを作る。
\&    （４）上記３）が２単位以上連続している場合に専門用語とする。
\&    （５）重要度の計算は、上記３）の単位で行う
.Ve
.SH "SEE ALSO"
.IX Header "SEE ALSO"
.Vb 9
\&    TermExtract::Calc_Imp
\&    TermExtract::Chasen
\&    TermExtract::MeCab
\&    TermExtract::BrillsTagger
\&    TermExtract::EnglishPlainText
\&    TermExtract::ChainesPlainTextUC
\&    TermExtract::ChainesPlainTextGB
\&    TermExtract::ICTCLAS
\&    TermExtract::JapanesePlainTextEUC
.Ve
.SH "COPYRIGHT"
.IX Header "COPYRIGHT"
.Vb 5
\&    このプログラムは、東京大学 前田朗 (maeda@lib.u\-tokyo.ac.jp)が作成し
\&  たものである。この専門用語抽出のアイデアは東京大学 中川裕志教授の中文
\&  ストップワード方式による専門用語重要度計算の理論と、「正規表e現とテキス
\&  ト・マイニング」(佐良木昌編、新田義彦著 明石書店 2003.10）に記載されて
\&  いたカタカナ・漢字抽出によるキーワード切り出しのアイデアを元にしている。
.Ve
.PP
.Vb 2
\&    なお、本プログラムの使用において生じたいかなる結果に関しても当方では
\&  一切責任を負わない。
.Ve
